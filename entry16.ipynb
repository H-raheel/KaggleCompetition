{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87171,"databundleVersionId":9897270,"sourceType":"competition"},{"sourceId":9700213,"sourceType":"datasetVersion","datasetId":5931692}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nfrom sklearn.metrics import  roc_auc_score\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.tree import DecisionTreeClassifier\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-23T11:40:54.446214Z","iopub.execute_input":"2024-10-23T11:40:54.446641Z","iopub.status.idle":"2024-10-23T11:40:55.902423Z","shell.execute_reply.started":"2024-10-23T11:40:54.446597Z","shell.execute_reply":"2024-10-23T11:40:55.901167Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\n\ntrain_set = pd.read_csv(\"/kaggle/input/dataset/train_set.csv\")\ntest_set = pd.read_csv(\"/kaggle/input/dataset/test_set.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:40:57.194608Z","iopub.execute_input":"2024-10-23T11:40:57.195225Z","iopub.status.idle":"2024-10-23T11:41:04.400741Z","shell.execute_reply.started":"2024-10-23T11:40:57.195179Z","shell.execute_reply":"2024-10-23T11:41:04.399154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# Find missing values in the training set\nmissing_values = train_set.isnull().sum()\nprint(missing_values[missing_values > 0])\n\n# Find missing values in the test set\nmissing_values = test_set.isnull().sum()\nprint(missing_values[missing_values > 0])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:41:04.403291Z","iopub.execute_input":"2024-10-23T11:41:04.403805Z","iopub.status.idle":"2024-10-23T11:41:04.479552Z","shell.execute_reply.started":"2024-10-23T11:41:04.403749Z","shell.execute_reply":"2024-10-23T11:41:04.476949Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"X2     2590\nX3     2139\nX75     456\nX76     444\nX77     447\nX78     447\ndtype: int64\nX2     1085\nX3      971\nX75     186\nX76     198\nX77     195\nX78     195\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"categorical_cols = []\nnumerical_cols = []\n\nfor column in train_set.columns:\n  if train_set[column].dtype == object or train_set[column].nunique() < 10:\n    categorical_cols.append(column)\n  else:\n    numerical_cols.append(column)\n\nprint(\"Categorical Columns:\", categorical_cols)\nprint(\"Numerical Columns:\", numerical_cols)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:41:04.481994Z","iopub.execute_input":"2024-10-23T11:41:04.482903Z","iopub.status.idle":"2024-10-23T11:41:05.340484Z","shell.execute_reply.started":"2024-10-23T11:41:04.482826Z","shell.execute_reply":"2024-10-23T11:41:05.339142Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Categorical Columns: ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16', 'Y']\nNumerical Columns: ['RecordId', 'X2', 'X3', 'X7', 'X9', 'X12', 'X13', 'X14', 'X15', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62', 'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle missing values for both train and test datasets\nfor column in categorical_cols:\n  if column in train_set.columns and train_set[column].isnull().any():\n    mode_imputer = SimpleImputer(strategy='most_frequent')\n    train_set[column] = mode_imputer.fit_transform(train_set[[column]])\n  if column in test_set.columns and test_set[column].isnull().any():\n    if column in train_set.columns:\n      mode_imputer = SimpleImputer(strategy='most_frequent')\n      test_set[column] = mode_imputer.fit_transform(test_set[[column]])\n    else:\n      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n\nfor column in numerical_cols:\n  if column in train_set.columns and train_set[column].isnull().any():\n    mean_imputer = SimpleImputer(strategy='mean')\n    train_set[column] = mean_imputer.fit_transform(train_set[[column]])\n  if column in test_set.columns and test_set[column].isnull().any():\n    if column in train_set.columns:\n      mean_imputer = SimpleImputer(strategy='mean')\n      test_set[column] = mean_imputer.fit_transform(test_set[[column]])\n    else:\n      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:41:09.970259Z","iopub.execute_input":"2024-10-23T11:41:09.970684Z","iopub.status.idle":"2024-10-23T11:41:10.027755Z","shell.execute_reply.started":"2024-10-23T11:41:09.970641Z","shell.execute_reply":"2024-10-23T11:41:10.026449Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Find missing values in the training set\nmissing_values = train_set.isnull().sum()\nprint(missing_values[missing_values > 0])\n\n# Find missing values in the test set\nmissing_values = test_set.isnull().sum()\nprint(missing_values[missing_values > 0])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:41:12.562725Z","iopub.execute_input":"2024-10-23T11:41:12.563269Z","iopub.status.idle":"2024-10-23T11:41:12.614325Z","shell.execute_reply.started":"2024-10-23T11:41:12.563223Z","shell.execute_reply":"2024-10-23T11:41:12.612816Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Series([], dtype: int64)\nSeries([], dtype: int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Assuming train_set and test_set are pandas DataFrames\n# Get all columns except 'Y' for X\nX = train_set[[col for col in train_set.columns if col != 'Y']]\n\n# Get only 'Y' column for y\ny = train_set['Y']\n\n# Select the same features for the test data\nX_testdata = test_set[[col for col in test_set.columns if col != 'Y']]\nif 'RecordId' in X.columns:\n  X = X.drop('RecordId', axis=1)\nif 'RecordId' in X_testdata.columns:\n  X_testdata = X_testdata.drop('RecordId', axis=1)\n\n# ... rest of your code (scaling, feature selection, model training, etc.) ...\nX.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-23T12:57:37.364035Z","iopub.execute_input":"2024-10-23T12:57:37.364469Z","iopub.status.idle":"2024-10-23T12:57:37.527275Z","shell.execute_reply.started":"2024-10-23T12:57:37.364428Z","shell.execute_reply":"2024-10-23T12:57:37.526041Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"selected_features = ['X5', 'X6','X8', 'X11', 'X14','X19', 'X22']\n\n# Keep only the selected features in X\nX = X[[col for col in X.columns if col in selected_features]]\n\n# Keep the same selected features in X_testdata\nX_testdata = X_testdata[[col for col in X_testdata.columns if col in selected_features]]\nX.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-23T12:57:46.401826Z","iopub.execute_input":"2024-10-23T12:57:46.402283Z","iopub.status.idle":"2024-10-23T12:57:46.419502Z","shell.execute_reply.started":"2024-10-23T12:57:46.402240Z","shell.execute_reply":"2024-10-23T12:57:46.417905Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Index(['X5', 'X6', 'X8', 'X11', 'X14', 'X19', 'X22'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"scalar=MinMaxScaler()\nX = scalar.fit_transform(X)\nX_testdata = scalar.transform(X_testdata)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T12:57:50.860948Z","iopub.execute_input":"2024-10-23T12:57:50.861375Z","iopub.status.idle":"2024-10-23T12:57:50.892325Z","shell.execute_reply.started":"2024-10-23T12:57:50.861337Z","shell.execute_reply":"2024-10-23T12:57:50.891330Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:42:48.920781Z","iopub.execute_input":"2024-10-23T11:42:48.921261Z","iopub.status.idle":"2024-10-23T11:42:48.969591Z","shell.execute_reply.started":"2024-10-23T11:42:48.921215Z","shell.execute_reply":"2024-10-23T11:42:48.968290Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(\n    n_estimators=1000,  #  number of trees\n    max_depth=5,       # Limit tree depth to control overfitting\n    min_samples_split=50,  # Minimum samples required to split\n    min_samples_leaf=500,    # Minimum samples required at a leaf node\n    max_features='sqrt',   # Randomly select a subset of features\n    random_state=42,\n    n_jobs=-1\n)\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:04:01.108091Z","iopub.execute_input":"2024-10-23T13:04:01.109495Z","iopub.status.idle":"2024-10-23T13:04:05.455847Z","shell.execute_reply.started":"2024-10-23T13:04:01.109441Z","shell.execute_reply":"2024-10-23T13:04:05.453952Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      3\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m      4\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,  \u001b[38;5;66;03m#  number of trees\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,       \u001b[38;5;66;03m# Limit tree depth to control overfitting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#with k-fold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Define the classifier\nclf = RandomForestClassifier(\n    n_estimators=1000,  # Number of trees\n    max_depth=20,        # Limit tree depth to control overfitting\n    min_samples_split=10,  # Minimum samples required to split\n    min_samples_leaf=2,    # Minimum samples required at a leaf node\n    max_features='sqrt',   # Randomly select a subset of features\n    random_state=42,\n    n_jobs=-1\n)\n\n# Define K-Fold cross-validator\nkfold = KFold(n_splits=20, shuffle=True, random_state=1)  # 10 folds\n\n# Perform cross-validation on training data\ncv_scores = cross_val_score(clf, X_train, y_train, cv=kfold, scoring='roc_auc')\n\n# Output cross-validation results\nprint(f\"Cross-validation Mean accuracy: {cv_scores.mean():.4f}\")\nprint(f\"Cross-validation Standard deviation: {cv_scores.std():.4f}\")\n\n# Train the classifier on the full training set and evaluate on the test set\nclf.fit(X_train, y_train)\n# test_accuracy = clf.score(X_test, y_test)\n\n# # Output test accuracy\n# print(f\"Test accuracy: {test_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:04:11.801152Z","iopub.execute_input":"2024-10-23T13:04:11.802167Z","iopub.status.idle":"2024-10-23T13:35:54.008017Z","shell.execute_reply.started":"2024-10-23T13:04:11.802120Z","shell.execute_reply":"2024-10-23T13:35:54.006754Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Cross-validation Mean accuracy: 0.8936\nCross-validation Standard deviation: 0.0192\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=10,\n                       n_estimators=1000, n_jobs=-1, random_state=42)","text/html":"<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=10,\n                       n_estimators=1000, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=10,\n                       n_estimators=1000, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\nimport matplotlib.pyplot as plt\n\ny_pred = clf.predict(X_test)\ny_probs = clf.predict_proba(X_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_probs)\n\n\n\n# Calculate AUC\nauc_score = roc_auc_score(y_test, y_probs)\nprint(f'AUC: {auc_score}')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:35:54.010368Z","iopub.execute_input":"2024-10-23T13:35:54.010788Z","iopub.status.idle":"2024-10-23T13:35:58.244624Z","shell.execute_reply.started":"2024-10-23T13:35:54.010741Z","shell.execute_reply":"2024-10-23T13:35:58.243459Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"AUC: 0.8777020593708871\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Predict probabilities for the test set\ny_test_probs = clf.predict_proba(X_testdata)[:, 1]\n\n# Create a DataFrame with RecordId and predicted probabilities\ntest_set['Y_probability'] = y_test_probs\n\n# Save the DataFrame to a CSV file\ntest_set[['RecordId', 'Y_probability']].to_csv('test_set_with_probabilities.csv', index=False)\n\n\nimport pandas as pd\n\n# Read the generated CSV file\ncsv_file_path = 'test_set_with_probabilities.csv'\ntest_set_with_probabilities = pd.read_csv(csv_file_path)\n\n# Get unique values in the Y_probability column\nunique_y_probabilities = test_set_with_probabilities['Y_probability'].unique()\n\n# Print the unique values\nprint(unique_y_probabilities)\nprint(test_set_with_probabilities)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:41:23.863554Z","iopub.execute_input":"2024-10-23T13:41:23.864057Z","iopub.status.idle":"2024-10-23T13:41:28.603748Z","shell.execute_reply.started":"2024-10-23T13:41:23.864012Z","shell.execute_reply":"2024-10-23T13:41:28.602451Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[1.55806571e-04 1.03544591e-04 4.19086351e-05 ... 2.28932668e-04\n 5.35238972e-04 6.72697586e-04]\n        RecordId  Y_probability\n0         300001       0.000156\n1         300002       0.000104\n2         300003       0.000042\n3         300004       0.000000\n4         300005       0.000022\n...          ...            ...\n105477    405478       0.000000\n105478    405479       0.147932\n105479    405480       0.000000\n105480    405481       0.000673\n105481    405482       0.000032\n\n[105482 rows x 2 columns]\n","output_type":"stream"}]}]}