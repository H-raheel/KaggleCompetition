{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gfgv57kzELiG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier,StackingClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer,mean_squared_error\n",
    "#from catboost import CatBoostClassifier, Pool, cv\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bPwLILa5ELiJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\train_set.csv')\n",
    "test_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZPFWRnsELiK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxqiUOpEELiK",
    "outputId": "fe54ed8f-9984-4e20-eb39-4042ac108d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16', 'Y']\n",
      "Numerical Columns: ['RecordId', 'X2', 'X3', 'X7', 'X9', 'X12', 'X13', 'X14', 'X15', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62', 'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numerical_cols = []\n",
    "\n",
    "for column in train_set.columns:\n",
    "  if train_set[column].dtype == object or train_set[column].nunique() < 10:\n",
    "    categorical_cols.append(column)\n",
    "  else:\n",
    "    numerical_cols.append(column)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "print(\"Numerical Columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GL5KTIwhELiL",
    "outputId": "0878aecd-060c-4cff-95d9-5c7664500a6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values for both train and test datasets\n",
    "for column in categorical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    train_set[column] = mode_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "      test_set[column] = mode_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "for column in numerical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    train_set[column] = mean_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mean_imputer = SimpleImputer(strategy='mean')\n",
    "      test_set[column] = mean_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "\n",
    "# Find missing values in the training set\n",
    "missing_values = train_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Find missing values in the test set\n",
    "missing_values = test_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhg7DglLELiL",
    "outputId": "9ece3b73-1178-4162-860b-13f19287871a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
       "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
       "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
       "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
       "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
       "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
       "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
       "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming train_set and test_set are pandas DataFrames\n",
    "# Get all columns except 'Y' for X\n",
    "X = train_set[[col for col in train_set.columns if col != 'Y']]\n",
    "\n",
    "# Get only 'Y' column for y\n",
    "y = train_set['Y']\n",
    "\n",
    "# Select the same features for the test data\n",
    "X_testdata = test_set[[col for col in test_set.columns if col != 'Y']]\n",
    "if 'RecordId' in X.columns:\n",
    "  X = X.drop('RecordId', axis=1)\n",
    "if 'RecordId' in X_testdata.columns:\n",
    "  X_testdata = X_testdata.drop('RecordId', axis=1)\n",
    "\n",
    "# ... rest of your code (scaling, feature selection, model training, etc.) ...\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njx_b3_dELiM"
   },
   "outputs": [],
   "source": [
    "# scalar=MinMaxScaler()\n",
    "# X = scalar.fit_transform(X)\n",
    "# X_testdata = scalar.transform(X_testdata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpTqueoLRuwL",
    "outputId": "b8fbac59-4a4c-4501-d90a-9c94900c2641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features - AUC: 0.9447\n",
      "Top 15 features - AUC: 0.9555\n",
      "Top 20 features - AUC: 0.9579\n",
      "Top 25 features - AUC: 0.9611\n",
      "Top 30 features - AUC: 0.9632\n",
      "Top 35 features - AUC: 0.9625\n",
      "Top 40 features - AUC: 0.9634\n",
      "Top 45 features - AUC: 0.9629\n",
      "Top 50 features - AUC: 0.9631\n",
      "Top 55 features - AUC: 0.9641\n",
      "Top 60 features - AUC: 0.9644\n",
      "\n",
      "AUC scores for different feature counts:\n",
      "Top 10 features: AUC = 0.9447\n",
      "Top 15 features: AUC = 0.9555\n",
      "Top 20 features: AUC = 0.9579\n",
      "Top 25 features: AUC = 0.9611\n",
      "Top 30 features: AUC = 0.9632\n",
      "Top 35 features: AUC = 0.9625\n",
      "Top 40 features: AUC = 0.9634\n",
      "Top 45 features: AUC = 0.9629\n",
      "Top 50 features: AUC = 0.9631\n",
      "Top 55 features: AUC = 0.9641\n",
      "Top 60 features: AUC = 0.9644\n"
     ]
    }
   ],
   "source": [
    "# import lightgbm as lgb\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Initialize and train the LightGBM model on full feature set to get feature importances\n",
    "# clf = lgb.LGBMClassifier(\n",
    "#     objective='binary',\n",
    "#     metric='binary_logloss',\n",
    "#     boosting_type='gbdt',\n",
    "#     num_leaves=20,\n",
    "#     max_depth=4,\n",
    "#     learning_rate=0.03,\n",
    "#     n_estimators=376,\n",
    "#     subsample=0.7,\n",
    "#     colsample_bytree=0.5,\n",
    "#     min_child_weight=5,\n",
    "#     scale_pos_weight=1.1,\n",
    "#     reg_lambda=0.1,\n",
    "#     verbose=-1\n",
    "# )\n",
    "\n",
    "# # Fit the model on full data to get feature importances\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Get feature importances and create a DataFrame\n",
    "# feature_importances = clf.feature_importances_\n",
    "# feature_importances_df = pd.DataFrame({\n",
    "#     'Feature': X_train.columns,\n",
    "#     'Importance': feature_importances\n",
    "# })\n",
    "\n",
    "# # Sort the DataFrame by importance\n",
    "# feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Define different numbers of top features to test\n",
    "# feature_counts = [10, 15, 20, 25, 30,35,40,45,50,55,60]\n",
    "# auc_scores = {}\n",
    "\n",
    "# # Iterate over different numbers of top features\n",
    "# for n in feature_counts:\n",
    "#     # Select the top n features\n",
    "#     top_features = feature_importances_df['Feature'].head(n).tolist()\n",
    "\n",
    "#     # Subset the training and testing data to the top n features\n",
    "#     X_train_top = X_train[top_features]\n",
    "#     X_test_top = X_test[top_features]\n",
    "\n",
    "#     # Re-train the model with the top n features\n",
    "#     clf.fit(X_train_top, y_train)\n",
    "\n",
    "#     # Predict probabilities on the test set\n",
    "#     y_pred_proba = clf.predict_proba(X_test_top)[:, 1]\n",
    "\n",
    "#     # Calculate AUC score\n",
    "#     auc = roc_auc_score(y_test, y_pred_proba)\n",
    "#     auc_scores[n] = auc  # Store the AUC score for this number of features\n",
    "\n",
    "#     print(f\"Top {n} features - AUC: {auc:.4f}\")\n",
    "\n",
    "# # Print all AUC scores for comparison\n",
    "# print(\"\\nAUC scores for different feature counts:\")\n",
    "# for n, auc in auc_scores.items():\n",
    "#     print(f\"Top {n} features: AUC = {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wj301VsELiM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wRkbQoMDELiM"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "NFuNQUL9OlVv",
    "outputId": "3a1a2b7e-84ba-4494-bf6f-bb17a92299d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.03, max_depth=8, metric=&#x27;binary_logloss&#x27;,\n",
       "               min_data_in_leaf=50, n_estimators=1500, num_leaves=100,\n",
       "               objective=&#x27;binary&#x27;, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.03, max_depth=8, metric=&#x27;binary_logloss&#x27;,\n",
       "               min_data_in_leaf=50, n_estimators=1500, num_leaves=100,\n",
       "               objective=&#x27;binary&#x27;, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.03, max_depth=8, metric='binary_logloss',\n",
       "               min_data_in_leaf=50, n_estimators=1500, num_leaves=100,\n",
       "               objective='binary', verbose=-1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the LightGBM model\n",
    "clf = lgb.LGBMClassifier(  \n",
    "    objective= 'binary',\n",
    "    metric= 'binary_logloss',\n",
    "    boosting_type= 'gbdt',\n",
    "    num_leaves= 100,\n",
    "    max_depth= 8,\n",
    "    learning_rate= 0.03,\n",
    "    n_estimators= 1500,\n",
    "    \n",
    "    min_data_in_leaf=50,\n",
    "    \n",
    "    verbose= -1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJ1El570Rr6P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize the LightGBM model\n",
    "lgbm_clf = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='binary_logloss',\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=100,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=1500,\n",
    "    min_data_in_leaf=50,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Initialize the Bagging classifier with the LightGBM model as the base estimator\n",
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=lgbm_clf,\n",
    "    n_estimators=10,  # Number of base estimators in the ensemble\n",
    "    max_samples=0.8,  # Fraction of samples to draw from X to train each base estimator\n",
    "    max_features=0.8,  # Fraction of features to draw from X to train each base estimator\n",
    "    bootstrap=True,  # Whether samples are drawn with replacement\n",
    "    bootstrap_features=False,  # Whether features are drawn with replacement\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 means using all processors)\n",
    "    random_state=42  # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the Bagging classifier to the training data\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "y_pred_proba = bagging_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the AUC-ROC score\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meGHD5NcELiO",
    "outputId": "2527e9d7-afa9-41e4-e26a-9110de845b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Importance\n",
      "67     X69        5447\n",
      "30     X32        4392\n",
      "64     X66        4059\n",
      "68     X70        3624\n",
      "0       X2        3111\n",
      "..     ...         ...\n",
      "17     X19         106\n",
      "74     X76          86\n",
      "2       X4          30\n",
      "14     X16           5\n",
      "69     X71           3\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances_df)\n",
    "\n",
    "top_features = feature_importances_df['Feature'].head(40).tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkulpzgFNWL7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "vyN4-Zg5ELiO",
    "outputId": "cb05723f-846a-4f0a-f6bc-8006a0b6a78d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.03, max_depth=8, metric=&#x27;binary_logloss&#x27;,\n",
       "               min_data_in_leaf=50, n_estimators=1500, num_leaves=100,\n",
       "               objective=&#x27;binary&#x27;, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.03, max_depth=8, metric=&#x27;binary_logloss&#x27;,\n",
       "               min_data_in_leaf=50, n_estimators=1500, num_leaves=100,\n",
       "               objective=&#x27;binary&#x27;, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.03, max_depth=8, metric='binary_logloss',\n",
       "               min_data_in_leaf=50, n_estimators=1500, num_leaves=100,\n",
       "               objective='binary', verbose=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_top = X_train[top_features]\n",
    "X_test_top = X_test[top_features]\n",
    "X_testdata_top = X_testdata[top_features]\n",
    "\n",
    "# Re-train the model with the top features\n",
    "clf.fit(X_train_top, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-9GdFlGELiP",
    "outputId": "e6d8f7f7-c558-47f0-8779-10ff87110cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9260563177249185\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_top)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwNnYCIrELiP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jnwq4bxELiP",
    "outputId": "1f2c4baf-ab24-442e-b217-4ef0cd31753d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities saved to test_set_with_probabilities.csv\n",
      "[2.28597395e-03 3.28565037e-04 8.64616620e-05 ... 1.97305216e-01\n",
      " 1.10920409e-04 3.35045108e-05]\n",
      "        RecordId  Y_probability\n",
      "0         300001       0.002286\n",
      "1         300002       0.000329\n",
      "2         300003       0.000086\n",
      "3         300004       0.000540\n",
      "4         300005       0.000421\n",
      "...          ...            ...\n",
      "105477    405478       0.000056\n",
      "105478    405479       0.197305\n",
      "105479    405480       0.000111\n",
      "105480    405481       0.000034\n",
      "105481    405482       0.000232\n",
      "\n",
      "[105482 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for the test set\n",
    "y_pred_proba_testdata = clf.predict_proba(X_testdata_top)[:, 1]\n",
    "\n",
    "# Create a DataFrame with RecordId and predicted probabilities\n",
    "test_set['Y_probability'] = y_pred_proba_testdata\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "test_set[['RecordId', 'Y_probability']].to_csv('test_set_with_probabilities.csv', index=False)\n",
    "\n",
    "print(\"Probabilities saved to test_set_with_probabilities.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the generated CSV file\n",
    "csv_file_path = 'test_set_with_probabilities.csv'\n",
    "test_set_with_probabilities = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get unique values in the Y_probability column\n",
    "unique_y_probabilities = test_set_with_probabilities['Y_probability'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_y_probabilities)\n",
    "print(test_set_with_probabilities)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
