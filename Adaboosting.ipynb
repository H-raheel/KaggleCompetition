{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfgv57kzELiG",
    "outputId": "aa706b1e-d8d1-4966-e40a-73427a861e27"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier,StackingClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer,mean_squared_error\n",
    "#from catboost import CatBoostClassifier, Pool, cv\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bPwLILa5ELiJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\train_set.csv')\n",
    "test_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZPFWRnsELiK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxqiUOpEELiK",
    "outputId": "46d60872-9675-4e7c-b5c1-06f3b44a6c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16', 'Y']\n",
      "Numerical Columns: ['RecordId', 'X2', 'X3', 'X7', 'X9', 'X12', 'X13', 'X14', 'X15', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62', 'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numerical_cols = []\n",
    "\n",
    "for column in train_set.columns:\n",
    "  if train_set[column].dtype == object or train_set[column].nunique() < 10:\n",
    "    categorical_cols.append(column)\n",
    "  else:\n",
    "    numerical_cols.append(column)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "print(\"Numerical Columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GL5KTIwhELiL",
    "outputId": "fcd24262-c843-480f-a4ee-e8e4326e9da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values for both train and test datasets\n",
    "for column in categorical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    train_set[column] = mode_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "      test_set[column] = mode_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "for column in numerical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    train_set[column] = mean_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mean_imputer = SimpleImputer(strategy='mean')\n",
    "      test_set[column] = mean_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "\n",
    "# Find missing values in the training set\n",
    "missing_values = train_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Find missing values in the test set\n",
    "missing_values = test_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhg7DglLELiL",
    "outputId": "37430c4a-39cb-4aa1-fa5f-4223713c4e4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
       "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
       "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
       "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
       "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
       "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
       "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
       "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming train_set and test_set are pandas DataFrames\n",
    "# Get all columns except 'Y' for X\n",
    "X = train_set[[col for col in train_set.columns if col != 'Y']]\n",
    "\n",
    "# Get only 'Y' column for y\n",
    "y = train_set['Y']\n",
    "\n",
    "# Select the same features for the test data\n",
    "X_testdata = test_set[[col for col in test_set.columns if col != 'Y']]\n",
    "if 'RecordId' in X.columns:\n",
    "  X = X.drop('RecordId', axis=1)\n",
    "if 'RecordId' in X_testdata.columns:\n",
    "  X_testdata = X_testdata.drop('RecordId', axis=1)\n",
    "\n",
    "# ... rest of your code (scaling, feature selection, model training, etc.) ...\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "njx_b3_dELiM"
   },
   "outputs": [],
   "source": [
    "# scalar=MinMaxScaler()\n",
    "# X = scalar.fit_transform(X)\n",
    "# X_testdata = scalar.transform(X_testdata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpTqueoLRuwL",
    "outputId": "b8fbac59-4a4c-4501-d90a-9c94900c2641"
   },
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Initialize and train the LightGBM model on full feature set to get feature importances\n",
    "# clf = lgb.LGBMClassifier(\n",
    "#     objective='binary',\n",
    "#     metric='binary_logloss',\n",
    "#     boosting_type='gbdt',\n",
    "#     num_leaves=20,\n",
    "#     max_depth=4,\n",
    "#     learning_rate=0.03,\n",
    "#     n_estimators=376,\n",
    "#     subsample=0.7,\n",
    "#     colsample_bytree=0.5,\n",
    "#     min_child_weight=5,\n",
    "#     scale_pos_weight=1.1,\n",
    "#     reg_lambda=0.1,\n",
    "#     verbose=-1\n",
    "# )\n",
    "\n",
    "# # Fit the model on full data to get feature importances\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Get feature importances and create a DataFrame\n",
    "# feature_importances = clf.feature_importances_\n",
    "# feature_importances_df = pd.DataFrame({\n",
    "#     'Feature': X_train.columns,\n",
    "#     'Importance': feature_importances\n",
    "# })\n",
    "\n",
    "# # Sort the DataFrame by importance\n",
    "# feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Define different numbers of top features to test\n",
    "# feature_counts = [10, 15, 20, 25, 30,35,40,45,50,55,60]\n",
    "# auc_scores = {}\n",
    "\n",
    "# # Iterate over different numbers of top features\n",
    "# for n in feature_counts:\n",
    "#     # Select the top n features\n",
    "#     top_features = feature_importances_df['Feature'].head(n).tolist()\n",
    "\n",
    "#     # Subset the training and testing data to the top n features\n",
    "#     X_train_top = X_train[top_features]\n",
    "#     X_test_top = X_test[top_features]\n",
    "\n",
    "#     # Re-train the model with the top n features\n",
    "#     clf.fit(X_train_top, y_train)\n",
    "\n",
    "#     # Predict probabilities on the test set\n",
    "#     y_pred_proba = clf.predict_proba(X_test_top)[:, 1]\n",
    "\n",
    "#     # Calculate AUC score\n",
    "#     auc = roc_auc_score(y_test, y_pred_proba)\n",
    "#     auc_scores[n] = auc  # Store the AUC score for this number of features\n",
    "\n",
    "#     print(f\"Top {n} features - AUC: {auc:.4f}\")\n",
    "\n",
    "# # Print all AUC scores for comparison\n",
    "# print(\"\\nAUC scores for different feature counts:\")\n",
    "# for n, auc in auc_scores.items():\n",
    "#     print(f\"Top {n} features: AUC = {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wj301VsELiM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wRkbQoMDELiM"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2EMpIV7RELiN"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# import xgboost as xgb\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.03, 0.1],\n",
    "#     'max_depth': [4, 6, 8],\n",
    "#     'n_estimators': [100, 200, 376,500],\n",
    "#     'gamma': [0, 0.1, 0.2],\n",
    "#     'reg_lambda': [0.01, 0.1, 1],\n",
    "#     'min_child_weight': [1, 3, 5],\n",
    "#     'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "#     'colsample_bylevel': [0.5, 0.7, 1.0],\n",
    "#     'scale_pos_weight': [1, 1.1, 1.2],\n",
    "#     'subsample': [0.7, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize the classifier\n",
    "# clf = xgb.XGBClassifier(\n",
    "#     objective='binary:logistic',\n",
    "#     eval_metric='logloss',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, cv=3, n_iter=50, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "# # Fit the model\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best parameters found: \", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z7EmjQZTEkeW"
   },
   "outputs": [],
   "source": [
    "# # prompt: like the following geneerate good params for catboost but stire separately:import xgboost as xgb\n",
    "# # from sklearn.model_selection import GridSearchCV\n",
    "# # # Define the parameter grid\n",
    "# # param_grid = {\n",
    "# #     'learning_rate': [0.01, 0.03, 0.1],\n",
    "# #     'max_depth': [4, 6, 8],\n",
    "# #     'n_estimators': [100, 200, 376,500],\n",
    "# #     'gamma': [0, 0.1, 0.2],\n",
    "# #     'reg_lambda': [0.01, 0.1, 1],\n",
    "# #     'min_child_weight': [1, 3, 5],\n",
    "# #     'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "# #     'colsample_bylevel': [0.5, 0.7, 1.0],\n",
    "# #     'scale_pos_weight': [1, 1.1, 1.2],\n",
    "# #     'subsample': [0.7, 0.8, 1.0]\n",
    "# # }\n",
    "# # # Initialize the classifier\n",
    "# # clf = xgb.XGBCla\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# import json\n",
    "\n",
    "# # Assuming X_train, y_train are defined from your previous code\n",
    "\n",
    "# # Define the parameter grid for CatBoost\n",
    "# param_grid = {\n",
    "#     'iterations': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'l2_leaf_reg': [1, 3, 5],\n",
    "#     'border_count': [32, 64, 128],\n",
    "#     'random_strength': [1, 1.5, 2],\n",
    "#     'bagging_temperature': [0, 1, 2],\n",
    "# }\n",
    "\n",
    "# # Initialize the CatBoost classifier\n",
    "# clf2 = CatBoostClassifier(\n",
    "#     loss_function='Logloss',\n",
    "#     eval_metric='AUC',\n",
    "#     task_type='GPU',  # Use GPU if available\n",
    "#     random_seed=42\n",
    "# )\n",
    "\n",
    "\n",
    "# # Initialize GridSearchCV for CatBoost\n",
    "# grid_search2 = GridSearchCV(estimator=clf2, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search2.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best parameters found: \", grid_search2.best_params_)\n",
    "\n",
    "# # Store the best parameters in a JSON file\n",
    "# best_params2 = grid_search2.best_params_\n",
    "# with open('best_catboost_params.json', 'w') as f:\n",
    "#     json.dump(best_params2, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "DASk166tDyVN",
    "outputId": "a9d86cc2-f20e-4f55-da1b-f14037c08f4b"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# # Define the parameter grid for LightGBM\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.03, 0.1],\n",
    "#     'max_depth': [4, 6, 8, -1],  # -1 indicates no limit for depth in LightGBM\n",
    "#     'n_estimators': [100, 200, 376, 500],\n",
    "#     'num_leaves': [20, 31, 40, 50],  # Controls complexity in LightGBM\n",
    "#     'reg_lambda': [0.01, 0.1, 1],\n",
    "#     'min_child_weight': [1, 3, 5],\n",
    "#     'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "#     'subsample': [0.7, 0.8, 1.0],\n",
    "#     'scale_pos_weight': [1, 1.1, 1.2]\n",
    "# }\n",
    "\n",
    "# # Initialize the classifier\n",
    "# clf = lgb.LGBMClassifier(\n",
    "#     objective='binary',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=clf,\n",
    "#     param_distributions=param_grid,\n",
    "#     cv=3,\n",
    "#     n_iter=50,\n",
    "#     scoring='roc_auc',\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit the model\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best parameters found: \", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "okZsY6SIELiN"
   },
   "outputs": [],
   "source": [
    "# clf =xgb.XGBClassifier(\n",
    "#       subsample=1.0,\n",
    "#       scale_pos_weight= 1.2,\n",
    "#       reg_lambda= 0.01,\n",
    "#       n_estimators= 500,\n",
    "#       min_child_weight= 5,\n",
    "#       max_depth= 6,\n",
    "#       learning_rate= 0.03,\n",
    "#       gamma= 0.2,\n",
    "#       colsample_bytree= 0.7,\n",
    "#       colsample_bylevel=0.7,\n",
    "#       objective='binary:logistic',\n",
    "#     eval_metric='logloss',\n",
    "#     random_state=42\n",
    "\n",
    "# )\n",
    "\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhFlmfFKjea-",
    "outputId": "7ae240f5-b152-4e7e-e04d-91cc06bb1615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
      "Best parameters found:  {'n_estimators': 100, 'learning_rate': 1.0, 'estimator__min_samples_split': 2, 'estimator__max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define a smaller parameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator__max_depth': [1, 2, 3],\n",
    "    'estimator__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost classifier with a DecisionTree as the base estimator\n",
    "model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Set up RandomizedSearchCV with fewer iterations and cross-validation folds\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    cv=2,  # Reduced from 3 to 2\n",
    "    n_iter=20,  # Reduced from 50 to 20\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ue7FHLYakYHv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with simplified parameters.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize a new AdaBoost model with simplified parameters\n",
    "clf = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(\n",
    "        max_depth=4,  # Reduced max_depth\n",
    "        min_samples_split=5,  # Increased min_samples_split\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_estimators=120,  # Reduced number of estimators\n",
    "    learning_rate=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with the best parameters on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Optionally, evaluate the model on the training or validation set\n",
    "print(\"Model trained with simplified parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "NFuNQUL9OlVv",
    "outputId": "35c22464-2864-451c-8dff-207ad7caffe1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, min_samples_split=5, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, min_samples_split=5, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# # Initialize the LightGBM model\n",
    "# clf = lgb.LGBMClassifier(  objective= 'binary',\n",
    "#     metric= 'binary_logloss',\n",
    "#     boosting_type= 'gbdt',\n",
    "#     num_leaves= 20,\n",
    "#     max_depth= 5,\n",
    "#     learning_rate= 0.03,\n",
    "#     n_estimators= 500,\n",
    "#     subsample= 0.7,\n",
    "#     colsample_bytree= 0.5,\n",
    "#     min_child_weight= 5,\n",
    "#     scale_pos_weight= 1.1,\n",
    "#     reg_lambda= 0.1,\n",
    "#     verbose= -1)\n",
    "\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJ1El570Rr6P"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# # Initialize Sequential Feature Selector\n",
    "# sfs = SequentialFeatureSelector(\n",
    "#     clf,\n",
    "#     direction='forward',\n",
    "#     n_features_to_select=10,\n",
    "#     scoring='roc_auc',\n",
    "#     cv=5  # Cross-validation\n",
    "# )\n",
    "\n",
    "# # Fit the Sequential Feature Selector\n",
    "# sfs.fit(X_train, y_train)\n",
    "\n",
    "# # Get selected feature indices and names\n",
    "# selected_features = sfs.get_support(indices=True)\n",
    "# selected_feature_names = X_train.columns[selected_features]\n",
    "\n",
    "# print(\"Selected Features:\", selected_feature_names.tolist())\n",
    "\n",
    "# top_features = selected_feature_names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJh_go8QlfPn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "meGHD5NcELiO"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for feature importances\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m feature_importances_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_importances\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Sort the DataFrame by importance\u001b[39;00m\n\u001b[0;32m     10\u001b[0m feature_importances_df \u001b[38;5;241m=\u001b[39m feature_importances_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances_df)\n",
    "\n",
    "#top_features = feature_importances_df['Feature'].head(50).tolist()\n",
    "top_features_2=feature_importances_df['Feature'].head(30).tolist()\n",
    "top_features=top_features_2\n",
    "##20-->  0.9419342388068738\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkulpzgFNWL7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX12JdP46fNh"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier  # Or your preferred classifier\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # Initialize variables\n",
    "# selected_features = []\n",
    "# remaining_features = X_train.columns.tolist()\n",
    "# top_features = []  # Store selected top features\n",
    "# max_features = 15  # Define the maximum number of features to select\n",
    "\n",
    "# # Perform forward selection using AUC-ROC as the scoring metric\n",
    "# for i in range(max_features):\n",
    "#     scores = []\n",
    "#     # Test each remaining feature by adding it to the selected_features\n",
    "#     for feature in remaining_features:\n",
    "#         # Define the current set of features\n",
    "#         current_features = selected_features + [feature]\n",
    "\n",
    "#         # Perform cross-validation using only the current set of features\n",
    "#         score = cross_val_score(clf, X_train[current_features], y_train, cv=5, scoring='roc_auc').mean()\n",
    "#         scores.append((feature, score))\n",
    "\n",
    "#     # Find the feature with the best score\n",
    "#     best_feature, best_feature_score = max(scores, key=lambda x: x[1])\n",
    "\n",
    "#     # If we still want to select features, update selected_features\n",
    "#     selected_features.append(best_feature)\n",
    "#     remaining_features.remove(best_feature)\n",
    "#     top_features.append(best_feature)\n",
    "\n",
    "# # Output the selected top features\n",
    "# print(\"Top selected features:\", top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vyN4-Zg5ELiO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=120, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=120, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, min_samples_split=5, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, min_samples_split=5, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=120, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_top = X_train[top_features]\n",
    "X_test_top = X_test[top_features]\n",
    "X_testdata_top = X_testdata[top_features]\n",
    "\n",
    "# Re-train the model with the top features\n",
    "clf.fit(X_train_top, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "w-9GdFlGELiP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9383578113572223\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_top)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, min_samples_split=5, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, min_samples_split=5, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         min_samples_split=5,\n",
       "                                                         random_state=42),\n",
       "                   learning_rate=0.01, n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwNnYCIrELiP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_Jnwq4bxELiP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities saved to test_set_with_probabilities.csv\n",
      "[0.00914844 0.01893653 0.00622982 ... 0.02529458 0.00837391 0.00919426]\n",
      "        RecordId  Y_probability\n",
      "0         300001       0.009148\n",
      "1         300002       0.018937\n",
      "2         300003       0.006230\n",
      "3         300004       0.010837\n",
      "4         300005       0.011101\n",
      "...          ...            ...\n",
      "105477    405478       0.006407\n",
      "105478    405479       0.221385\n",
      "105479    405480       0.016206\n",
      "105480    405481       0.015919\n",
      "105481    405482       0.006729\n",
      "\n",
      "[105482 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for the test set\n",
    "y_pred_proba_testdata = clf.predict_proba(X_testdata_top)[:, 1]\n",
    "\n",
    "# Create a DataFrame with RecordId and predicted probabilities\n",
    "test_set['Y_probability'] = y_pred_proba_testdata\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "test_set[['RecordId', 'Y_probability']].to_csv('test_set_with_probabilities.csv', index=False)\n",
    "\n",
    "print(\"Probabilities saved to test_set_with_probabilities.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the generated CSV file\n",
    "csv_file_path = 'test_set_with_probabilities.csv'\n",
    "test_set_with_probabilities = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get unique values in the Y_probability column\n",
    "unique_y_probabilities = test_set_with_probabilities['Y_probability'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_y_probabilities)\n",
    "print(test_set_with_probabilities)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
