{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfgv57kzELiG",
    "outputId": "f6079e18-9ee5-411e-b832-73f1ff2e92ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier,StackingClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer,mean_squared_error\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bPwLILa5ELiJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\train_set.csv')\n",
    "test_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZPFWRnsELiK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxqiUOpEELiK",
    "outputId": "2face4d9-da80-4b2e-ff54-ddcfeff0b87e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16', 'Y']\n",
      "Numerical Columns: ['RecordId', 'X2', 'X3', 'X7', 'X9', 'X12', 'X13', 'X14', 'X15', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62', 'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numerical_cols = []\n",
    "\n",
    "for column in train_set.columns:\n",
    "  if train_set[column].dtype == object or train_set[column].nunique() < 10:\n",
    "    categorical_cols.append(column)\n",
    "  else:\n",
    "    numerical_cols.append(column)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "print(\"Numerical Columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GL5KTIwhELiL",
    "outputId": "77d3d5a4-7a83-4dc4-e931-c5cf4f233391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values for both train and test datasets\n",
    "for column in categorical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    train_set[column] = mode_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "      test_set[column] = mode_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "for column in numerical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    train_set[column] = mean_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mean_imputer = SimpleImputer(strategy='mean')\n",
    "      test_set[column] = mean_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "\n",
    "# Find missing values in the training set\n",
    "missing_values = train_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Find missing values in the test set\n",
    "missing_values = test_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhg7DglLELiL",
    "outputId": "39084e2b-f486-495e-8b58-06fa1aade20a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
       "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
       "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
       "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
       "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
       "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
       "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
       "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming train_set and test_set are pandas DataFrames\n",
    "# Get all columns except 'Y' for X\n",
    "X = train_set[[col for col in train_set.columns if col != 'Y']]\n",
    "\n",
    "# Get only 'Y' column for y\n",
    "y = train_set['Y']\n",
    "\n",
    "# Select the same features for the test data\n",
    "X_testdata = test_set[[col for col in test_set.columns if col != 'Y']]\n",
    "if 'RecordId' in X.columns:\n",
    "  X = X.drop('RecordId', axis=1)\n",
    "if 'RecordId' in X_testdata.columns:\n",
    "  X_testdata = X_testdata.drop('RecordId', axis=1)\n",
    "\n",
    "# ... rest of your code (scaling, feature selection, model training, etc.) ...\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "njx_b3_dELiM"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scale the data\n",
    "scalar = MinMaxScaler()\n",
    "X = scalar.fit_transform(X)\n",
    "X_testdata = scalar.transform(X_testdata)\n",
    "\n",
    "# Apply PCA\n",
    "# pca = PCA(n_components=20)  # Retain 95% of the variance\n",
    "# X = pca.fit_transform(X)\n",
    "# X_testdata = pca.transform(X_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wj301VsELiM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wRkbQoMDELiM"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "okZsY6SIELiN",
    "outputId": "48938163-189f-4cb4-e453-257dcc5b9d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "AUC Score: 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Initialize KNN Classifier with optimized parameters\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,       # Increase the number of neighbors to use\n",
    "    weights='distance',   # Weight points by the inverse of their distance\n",
    "    algorithm='auto',     # Algorithm to compute the nearest neighbors\n",
    "    leaf_size=20,         # Decrease leaf size for BallTree or KDTree\n",
    "    p=1,                  # Use Manhattan distance (L1 norm)\n",
    "    n_jobs=-1             # Use all available cores\n",
    ")\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Predict the probabilities for the test set\n",
    "y_prob = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the AUC score of the classifier\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meGHD5NcELiO",
    "outputId": "7ff415a2-074b-44c7-fb4a-2bad5df7adb5"
   },
   "outputs": [],
   "source": [
    "# # Get feature importances\n",
    "# feature_importances = clf.feature_importances_\n",
    "\n",
    "# # Create a DataFrame for feature importances\n",
    "# feature_importances_df = pd.DataFrame({\n",
    "#     'Feature': X_train.columns,\n",
    "#     'Importance': feature_importances\n",
    "# })\n",
    "\n",
    "# # Sort the DataFrame by importance\n",
    "# feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Print the feature importances\n",
    "# print(feature_importances_df)\n",
    "\n",
    "# top_features = feature_importances_df['Feature'].head(45).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "vyN4-Zg5ELiO",
    "outputId": "43b472f3-bbaf-45cd-ff45-83e0ee7ecf5e"
   },
   "outputs": [],
   "source": [
    "# X_train_top = X_train[top_features]\n",
    "# X_test_top = X_test[top_features]\n",
    "# X_testdata_top = X_testdata[top_features]\n",
    "\n",
    "# # Re-train the model with the top features\n",
    "# clf.fit(X_train_top, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PwNnYCIrELiP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(leaf_size=20, n_jobs=-1, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=20, n_jobs=-1, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(leaf_size=20, n_jobs=-1, p=1, weights='distance')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jnwq4bxELiP",
    "outputId": "34926f43-378a-41d1-e40a-ab7d5ef87a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities saved to test_set_with_probabilities.csv\n",
      "[0.         0.1429095  0.10377412 0.1450159  0.191526   0.18178828\n",
      " 0.20242189 0.20260749 0.06035764 0.18423939 0.13883167 0.13065585\n",
      " 0.18913208 0.18510061 0.17620153 0.20405237 0.19188206 0.19004335\n",
      " 0.13151494 0.09523171 0.18912173 0.20455939 0.20128701 0.17702158\n",
      " 0.18934943 0.12679847 0.06908686 0.18743729 0.17257826 0.15541784\n",
      " 0.11412572 0.21470446 0.17785126 0.0744865  0.18991432 0.05885023\n",
      " 0.14690793 0.15770163 0.18106444 0.18593071 0.09269635 0.18617573\n",
      " 0.20354159 0.12658812 0.40607137 0.07971008 0.20005354 0.06029575\n",
      " 0.06978441 0.10741536 0.07866839 0.18582024 0.19918179 0.10729177\n",
      " 0.15110542 0.14179871 0.09822814 0.19374416 0.21914155 0.06451363\n",
      " 0.16222055 0.1716203  0.17677839 0.19087027 0.13624175 0.20476757\n",
      " 0.10733355 0.19481785 0.14637413 0.1714907  0.04459813 0.08732466\n",
      " 0.18601419 0.16369775 0.19991545 0.19391719 0.19899299 0.20645049\n",
      " 0.18453856 0.17139441 0.19396112 0.15816542 0.19441771 0.09987028\n",
      " 0.18450045 0.1594596  0.19612779 0.1953503  0.2200594  0.18899614\n",
      " 0.40151948 0.19756943 0.2017334  0.20778016 0.17258876 0.13914043\n",
      " 0.11499201 0.1856796  0.10760327 0.1451965  0.19316472 0.10392499\n",
      " 0.08099756 0.19135889 0.13066198 0.20303385 0.20250841 0.19715428\n",
      " 0.19685163 0.20059718 0.19467133 0.14367241 0.05018779 0.18948939\n",
      " 0.1621579  0.00386012 0.05988769 0.09411055 0.18099132 0.19506566\n",
      " 0.04706092 0.17855472 0.18225902 0.1942681  0.1962754  0.18946333\n",
      " 0.14185426 0.22428915 0.19753541 0.18866137 0.14104941 0.13981921\n",
      " 0.12669603 0.1288973  0.15057457 0.14782212 0.22792809 0.16632409\n",
      " 0.1252703  0.40150847 0.19596524 0.13038141 0.08304505 0.17255472\n",
      " 0.1258497  0.04994251 0.19803777 0.15355717 0.1498886  0.2003354\n",
      " 0.04220607 0.22831537 0.11963973 0.10127132 0.17626436 0.22429854\n",
      " 0.18484948 0.21319032 0.08104353 0.13807338 0.15348697 0.22102534\n",
      " 0.16868033 0.17185524 0.19917083 0.14550664 0.13472101 0.10183503\n",
      " 0.10672656 0.14842829 0.02767298 0.17293312 0.10120648 0.14302509\n",
      " 0.11003762 0.19866432 0.15800401 0.17197178 0.11058294 0.2095045\n",
      " 0.17565751 0.1836018  0.19189941 0.24013887 0.19282646 0.18596973\n",
      " 0.14363855 0.1533295  0.07767023 0.03338805 0.20508142 0.15597166\n",
      " 0.1855377  0.19731688 0.16504892 0.04645042 0.19531463 0.15139988\n",
      " 0.13443545 0.20078156 0.10294282 0.19847457 0.18156957 0.06848632\n",
      " 0.15872264 0.1871034  0.15056456 0.19327856 0.16573989 0.07193706\n",
      " 0.14353132 0.1835581  0.19839949 0.2197935  0.1699335  0.22039227\n",
      " 0.15635799 0.14025945 0.13848393 0.12641552 0.07498788 0.16392495\n",
      " 0.20809513 0.1118307  0.17490295 0.18605897 0.19952868 0.10538656\n",
      " 0.1468561  0.07112225 0.16150692 0.16139453 0.23741241 0.20756077\n",
      " 0.17151891 0.19576145 0.13210889 0.16040674 0.21038826 0.17141902\n",
      " 0.19564373 0.09113071 0.19559212 0.22361536 0.06846028 0.14436952\n",
      " 0.19481837 0.05236681 0.11538701 0.09858309 0.16343182 0.16344614\n",
      " 0.20210592 0.15224867 0.19193261 0.19823235 0.14631784 0.14080517\n",
      " 0.08301126 0.1663308  0.17777167 0.15409613 0.13664258 0.16560375\n",
      " 0.19520876 0.19011384 0.19162251 0.0415574  0.29761698 0.1153782\n",
      " 0.40746481 0.05570453 0.20573909 0.03588086 0.20545033 0.18178881\n",
      " 0.19020415 0.18186701 0.10095336 0.11744161 0.01756049 0.19415343\n",
      " 0.16051097 0.19604743 0.1502057  0.20183992 0.15180299 0.14016756\n",
      " 0.07559338 0.20033612 0.04417599 0.14949212 0.1838301  0.18203113\n",
      " 0.19196745 0.08374442 0.18271666 0.12638282 0.11360338 0.19343909\n",
      " 0.13394298 0.20341062 0.17737369 0.15994842 0.04846199 0.39469334\n",
      " 0.10518404 0.05739894 0.19649704 0.1408354  0.18157671 0.15664964\n",
      " 0.17477522 0.01754918 0.39655049 0.12886951 0.09760177 0.1349731\n",
      " 0.12652402 0.01045672 0.18030312 0.10198964 0.18763384 0.18269479\n",
      " 0.06945751 0.19895791 0.17460929 0.20816879 0.1087558  0.10924056\n",
      " 0.19927604 0.21307121 0.13605688 0.24410067 0.13837592 0.0987717\n",
      " 0.13971786 0.08573442 0.20145439 0.12983491 0.17287998 0.06382036\n",
      " 0.20157108 0.08088163 0.00846915 0.19608938 0.19747634 0.18313502\n",
      " 0.20522365 0.16769931 0.17011538 0.16235771 0.11313243 0.16922452\n",
      " 0.17559418 0.20103858 0.18404019 0.19340584 0.19791873 0.05653543\n",
      " 0.18932935 0.19238376 0.12908174 0.20776573 0.01534187 0.15000513\n",
      " 0.10122026 0.16038793]\n",
      "        RecordId  Y_probability\n",
      "0         300001            0.0\n",
      "1         300002            0.0\n",
      "2         300003            0.0\n",
      "3         300004            0.0\n",
      "4         300005            0.0\n",
      "...          ...            ...\n",
      "105477    405478            0.0\n",
      "105478    405479            0.0\n",
      "105479    405480            0.0\n",
      "105480    405481            0.0\n",
      "105481    405482            0.0\n",
      "\n",
      "[105482 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for the test set\n",
    "y_pred_proba_testdata = knn.predict_proba(X_testdata)[:, 1]\n",
    "\n",
    "# Create a DataFrame with RecordId and predicted probabilities\n",
    "test_set['Y_probability'] = y_pred_proba_testdata\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "test_set[['RecordId', 'Y_probability']].to_csv('test_set_with_probabilities.csv', index=False)\n",
    "\n",
    "print(\"Probabilities saved to test_set_with_probabilities.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the generated CSV file\n",
    "csv_file_path = 'test_set_with_probabilities.csv'\n",
    "test_set_with_probabilities = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get unique values in the Y_probability column\n",
    "unique_y_probabilities = test_set_with_probabilities['Y_probability'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_y_probabilities)\n",
    "print(test_set_with_probabilities)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
