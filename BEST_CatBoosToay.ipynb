{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfgv57kzELiG",
    "outputId": "0231b89b-b724-4210-8cb8-1206a841f660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: graphviz in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.26.1)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (2.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\hrahe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (8.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier,StackingClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer,mean_squared_error\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bPwLILa5ELiJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\train_set.csv')\n",
    "test_set = pd.read_csv(r'C:\\Users\\hrahe\\Downloads\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZPFWRnsELiK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxqiUOpEELiK",
    "outputId": "a283a22a-c66b-4e22-e161-cf80ceaea51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16', 'Y']\n",
      "Numerical Columns: ['RecordId', 'X2', 'X3', 'X7', 'X9', 'X12', 'X13', 'X14', 'X15', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62', 'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72', 'X73', 'X74', 'X75', 'X76', 'X77', 'X78']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "numerical_cols = []\n",
    "\n",
    "for column in train_set.columns:\n",
    "  if train_set[column].dtype == object or train_set[column].nunique() < 10:\n",
    "    categorical_cols.append(column)\n",
    "  else:\n",
    "    numerical_cols.append(column)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "print(\"Numerical Columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GL5KTIwhELiL",
    "outputId": "a66d7326-69a9-4504-cc67-f8c72a151b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values for both train and test datasets\n",
    "for column in categorical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    train_set[column] = mode_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "      test_set[column] = mode_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "for column in numerical_cols:\n",
    "  if column in train_set.columns and train_set[column].isnull().any():\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    train_set[column] = mean_imputer.fit_transform(train_set[[column]])\n",
    "  if column in test_set.columns and test_set[column].isnull().any():\n",
    "    if column in train_set.columns:\n",
    "      mean_imputer = SimpleImputer(strategy='mean')\n",
    "      test_set[column] = mean_imputer.fit_transform(test_set[[column]])\n",
    "    else:\n",
    "      print(f\"Warning: Column '{column}' is missing in the training set and cannot be imputed in the test set.\")\n",
    "\n",
    "\n",
    "# Find missing values in the training set\n",
    "missing_values = train_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Find missing values in the test set\n",
    "missing_values = test_set.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhg7DglLELiL",
    "outputId": "0ee9df00-42de-40bf-82ac-b610f78b91f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
       "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
       "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
       "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
       "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
       "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
       "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
       "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming train_set and test_set are pandas DataFrames\n",
    "# Get all columns except 'Y' for X\n",
    "X = train_set[[col for col in train_set.columns if col != 'Y']]\n",
    "\n",
    "# Get only 'Y' column for y\n",
    "y = train_set['Y']\n",
    "\n",
    "# Select the same features for the test data\n",
    "X_testdata = test_set[[col for col in test_set.columns if col != 'Y']]\n",
    "if 'RecordId' in X.columns:\n",
    "  X = X.drop('RecordId', axis=1)\n",
    "if 'RecordId' in X_testdata.columns:\n",
    "  X_testdata = X_testdata.drop('RecordId', axis=1)\n",
    "\n",
    "# ... rest of your code (scaling, feature selection, model training, etc.) ...\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
       "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
       "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
       "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
       "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
       "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
       "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
       "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=X.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "njx_b3_dELiM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of X before scaling: Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
      "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
      "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
      "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
      "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
      "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
      "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
      "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
      "      dtype='object')\n",
      "Columns of X after scaling: Index(['X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12',\n",
      "       'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22',\n",
      "       'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32',\n",
      "       'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40', 'X41', 'X42',\n",
      "       'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50', 'X51', 'X52',\n",
      "       'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60', 'X61', 'X62',\n",
      "       'X63', 'X64', 'X65', 'X66', 'X67', 'X68', 'X69', 'X70', 'X71', 'X72',\n",
      "       'X73', 'X74', 'X75', 'X76', 'X77', 'X78'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X and X_testdata are already defined as DataFrames\n",
    "# Show the columns of X\n",
    "print(\"Columns of X before scaling:\", X.columns)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_testdata_scaled = scaler.transform(X_testdata)\n",
    "\n",
    "# Convert the scaled arrays back to DataFrames to retain column names\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_testdata_scaled_df = pd.DataFrame(X_testdata_scaled, columns=X_testdata.columns)\n",
    "\n",
    "# Show the columns of the scaled DataFrame\n",
    "print(\"Columns of X after scaling:\", X_scaled_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2054797\ttotal: 198ms\tremaining: 26m 25s\n",
      "100:\tlearn: 0.0112351\ttotal: 2.32s\tremaining: 3m 1s\n",
      "200:\tlearn: 0.0100391\ttotal: 4.25s\tremaining: 2m 45s\n",
      "300:\tlearn: 0.0092536\ttotal: 6.38s\tremaining: 2m 43s\n",
      "400:\tlearn: 0.0086759\ttotal: 8.53s\tremaining: 2m 41s\n",
      "500:\tlearn: 0.0081726\ttotal: 10.7s\tremaining: 2m 39s\n",
      "600:\tlearn: 0.0077233\ttotal: 13s\tremaining: 2m 39s\n",
      "700:\tlearn: 0.0073306\ttotal: 15.2s\tremaining: 2m 38s\n",
      "800:\tlearn: 0.0069629\ttotal: 17.5s\tremaining: 2m 36s\n",
      "900:\tlearn: 0.0066207\ttotal: 19.7s\tremaining: 2m 35s\n",
      "1000:\tlearn: 0.0063149\ttotal: 23s\tremaining: 2m 40s\n",
      "1100:\tlearn: 0.0059791\ttotal: 25.3s\tremaining: 2m 38s\n",
      "1200:\tlearn: 0.0056370\ttotal: 28.1s\tremaining: 2m 39s\n",
      "1300:\tlearn: 0.0053583\ttotal: 30.9s\tremaining: 2m 39s\n",
      "1400:\tlearn: 0.0050901\ttotal: 33.2s\tremaining: 2m 36s\n",
      "1500:\tlearn: 0.0048448\ttotal: 36s\tremaining: 2m 35s\n",
      "1600:\tlearn: 0.0046042\ttotal: 38.5s\tremaining: 2m 33s\n",
      "1700:\tlearn: 0.0043804\ttotal: 41.1s\tremaining: 2m 32s\n",
      "1800:\tlearn: 0.0041562\ttotal: 44s\tremaining: 2m 31s\n",
      "1900:\tlearn: 0.0039561\ttotal: 47s\tremaining: 2m 30s\n",
      "2000:\tlearn: 0.0037362\ttotal: 49.9s\tremaining: 2m 29s\n",
      "2100:\tlearn: 0.0035409\ttotal: 52.7s\tremaining: 2m 27s\n",
      "2200:\tlearn: 0.0033695\ttotal: 54.9s\tremaining: 2m 24s\n",
      "2300:\tlearn: 0.0031820\ttotal: 57.1s\tremaining: 2m 21s\n",
      "2400:\tlearn: 0.0029918\ttotal: 59.3s\tremaining: 2m 18s\n",
      "2500:\tlearn: 0.0028398\ttotal: 1m 1s\tremaining: 2m 15s\n",
      "2600:\tlearn: 0.0026975\ttotal: 1m 3s\tremaining: 2m 12s\n",
      "2700:\tlearn: 0.0025662\ttotal: 1m 6s\tremaining: 2m 9s\n",
      "2800:\tlearn: 0.0024239\ttotal: 1m 10s\tremaining: 2m 10s\n",
      "2900:\tlearn: 0.0022893\ttotal: 1m 13s\tremaining: 2m 8s\n",
      "3000:\tlearn: 0.0021895\ttotal: 1m 16s\tremaining: 2m 6s\n",
      "3100:\tlearn: 0.0020737\ttotal: 1m 18s\tremaining: 2m 4s\n",
      "3200:\tlearn: 0.0019641\ttotal: 1m 21s\tremaining: 2m 2s\n",
      "3300:\tlearn: 0.0018667\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "3400:\tlearn: 0.0017698\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "3500:\tlearn: 0.0016786\ttotal: 1m 28s\tremaining: 1m 53s\n",
      "3600:\tlearn: 0.0015898\ttotal: 1m 30s\tremaining: 1m 50s\n",
      "3700:\tlearn: 0.0015032\ttotal: 1m 33s\tremaining: 1m 48s\n",
      "3800:\tlearn: 0.0014354\ttotal: 1m 35s\tremaining: 1m 45s\n",
      "3900:\tlearn: 0.0013686\ttotal: 1m 38s\tremaining: 1m 43s\n",
      "4000:\tlearn: 0.0012931\ttotal: 1m 41s\tremaining: 1m 41s\n",
      "4100:\tlearn: 0.0012242\ttotal: 1m 43s\tremaining: 1m 38s\n",
      "4200:\tlearn: 0.0011608\ttotal: 1m 45s\tremaining: 1m 35s\n",
      "4300:\tlearn: 0.0010975\ttotal: 1m 47s\tremaining: 1m 32s\n",
      "4400:\tlearn: 0.0010435\ttotal: 1m 50s\tremaining: 1m 30s\n",
      "4500:\tlearn: 0.0009862\ttotal: 1m 53s\tremaining: 1m 28s\n",
      "4600:\tlearn: 0.0009343\ttotal: 1m 56s\tremaining: 1m 25s\n",
      "4700:\tlearn: 0.0008942\ttotal: 1m 58s\tremaining: 1m 23s\n",
      "4800:\tlearn: 0.0008554\ttotal: 2m 1s\tremaining: 1m 20s\n",
      "4900:\tlearn: 0.0008107\ttotal: 2m 4s\tremaining: 1m 18s\n",
      "5000:\tlearn: 0.0007744\ttotal: 2m 6s\tremaining: 1m 15s\n",
      "5100:\tlearn: 0.0007408\ttotal: 2m 8s\tremaining: 1m 13s\n",
      "5200:\tlearn: 0.0007126\ttotal: 2m 10s\tremaining: 1m 10s\n",
      "5300:\tlearn: 0.0006782\ttotal: 2m 13s\tremaining: 1m 7s\n",
      "5400:\tlearn: 0.0006515\ttotal: 2m 15s\tremaining: 1m 5s\n",
      "5500:\tlearn: 0.0006259\ttotal: 2m 17s\tremaining: 1m 2s\n",
      "5600:\tlearn: 0.0006018\ttotal: 2m 20s\tremaining: 1m\n",
      "5700:\tlearn: 0.0005840\ttotal: 2m 22s\tremaining: 57.7s\n",
      "5800:\tlearn: 0.0005603\ttotal: 2m 25s\tremaining: 55s\n",
      "5900:\tlearn: 0.0005406\ttotal: 2m 27s\tremaining: 52.4s\n",
      "6000:\tlearn: 0.0005235\ttotal: 2m 29s\tremaining: 49.8s\n",
      "6100:\tlearn: 0.0005079\ttotal: 2m 31s\tremaining: 47.1s\n",
      "6200:\tlearn: 0.0004880\ttotal: 2m 33s\tremaining: 44.6s\n",
      "6300:\tlearn: 0.0004721\ttotal: 2m 35s\tremaining: 42s\n",
      "6400:\tlearn: 0.0004559\ttotal: 2m 37s\tremaining: 39.4s\n",
      "6500:\tlearn: 0.0004411\ttotal: 2m 39s\tremaining: 36.9s\n",
      "6600:\tlearn: 0.0004286\ttotal: 2m 42s\tremaining: 34.3s\n",
      "6700:\tlearn: 0.0004154\ttotal: 2m 44s\tremaining: 31.9s\n",
      "6800:\tlearn: 0.0004027\ttotal: 2m 46s\tremaining: 29.4s\n",
      "6900:\tlearn: 0.0003913\ttotal: 2m 48s\tremaining: 26.8s\n",
      "7000:\tlearn: 0.0003826\ttotal: 2m 50s\tremaining: 24.4s\n",
      "7100:\tlearn: 0.0003732\ttotal: 2m 52s\tremaining: 21.9s\n",
      "7200:\tlearn: 0.0003646\ttotal: 2m 54s\tremaining: 19.4s\n",
      "7300:\tlearn: 0.0003557\ttotal: 2m 56s\tremaining: 16.9s\n",
      "7400:\tlearn: 0.0003474\ttotal: 2m 58s\tremaining: 14.5s\n",
      "7500:\tlearn: 0.0003372\ttotal: 3m\tremaining: 12s\n",
      "7600:\tlearn: 0.0003272\ttotal: 3m 2s\tremaining: 9.61s\n",
      "7700:\tlearn: 0.0003189\ttotal: 3m 4s\tremaining: 7.18s\n",
      "7800:\tlearn: 0.0003126\ttotal: 3m 6s\tremaining: 4.77s\n",
      "7900:\tlearn: 0.0003058\ttotal: 3m 8s\tremaining: 2.37s\n",
      "7999:\tlearn: 0.0002990\ttotal: 3m 10s\tremaining: 0us\n",
      "Accuracy: 0.9970137125444388\n",
      "ROC AUC Score: 0.884342242081893\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize the CatBoost classifier with default parameters\n",
    "catboost_clf = CatBoostClassifier(\n",
    "    iterations=8000,\n",
    "    learning_rate=0.035,\n",
    "    depth=2,\n",
    "    random_seed=2,\n",
    "    verbose=100,\n",
    "   \n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "catboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = catboost_clf.predict(X_test)\n",
    "y_pred_proba = catboost_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 60 best features:\n",
      "Index(['X2', 'X3', 'X7', 'X9', 'X12', 'X13', 'X14', 'X15', 'X21', 'X23', 'X24',\n",
      "       'X26', 'X28', 'X31', 'X32', 'X37', 'X38', 'X40', 'X42', 'X44', 'X45',\n",
      "       'X46', 'X47', 'X51', 'X58', 'X60', 'X63', 'X64', 'X65', 'X66', 'X67',\n",
      "       'X68', 'X69', 'X70', 'X73'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hrahe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf=catboost_clf\n",
    "# Assuming clf is your trained model\n",
    "selector = SelectFromModel(clf, max_features=60, prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "X_testdata_selected = selector.transform(X_testdata)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "\n",
    "print(f\"Selected 60 best features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2055495\ttotal: 18.4ms\tremaining: 2m 27s\n",
      "100:\tlearn: 0.0114543\ttotal: 1.74s\tremaining: 2m 16s\n",
      "200:\tlearn: 0.0104737\ttotal: 3.61s\tremaining: 2m 20s\n",
      "300:\tlearn: 0.0097597\ttotal: 5.37s\tremaining: 2m 17s\n",
      "400:\tlearn: 0.0092084\ttotal: 7.12s\tremaining: 2m 14s\n",
      "500:\tlearn: 0.0087375\ttotal: 8.88s\tremaining: 2m 12s\n",
      "600:\tlearn: 0.0083234\ttotal: 10.6s\tremaining: 2m 10s\n",
      "700:\tlearn: 0.0079136\ttotal: 12.3s\tremaining: 2m 8s\n",
      "800:\tlearn: 0.0075276\ttotal: 14.1s\tremaining: 2m 6s\n",
      "900:\tlearn: 0.0071446\ttotal: 15.8s\tremaining: 2m 4s\n",
      "1000:\tlearn: 0.0068395\ttotal: 17.6s\tremaining: 2m 3s\n",
      "1100:\tlearn: 0.0065297\ttotal: 19.3s\tremaining: 2m 1s\n",
      "1200:\tlearn: 0.0062069\ttotal: 21.2s\tremaining: 1m 59s\n",
      "1300:\tlearn: 0.0059024\ttotal: 22.9s\tremaining: 1m 57s\n",
      "1400:\tlearn: 0.0056353\ttotal: 24.6s\tremaining: 1m 56s\n",
      "1500:\tlearn: 0.0053608\ttotal: 26.6s\tremaining: 1m 55s\n",
      "1600:\tlearn: 0.0050932\ttotal: 28.9s\tremaining: 1m 55s\n",
      "1700:\tlearn: 0.0048480\ttotal: 31.2s\tremaining: 1m 55s\n",
      "1800:\tlearn: 0.0046439\ttotal: 33.5s\tremaining: 1m 55s\n",
      "1900:\tlearn: 0.0044063\ttotal: 36.1s\tremaining: 1m 55s\n",
      "2000:\tlearn: 0.0041939\ttotal: 38.4s\tremaining: 1m 55s\n",
      "2100:\tlearn: 0.0040057\ttotal: 40.4s\tremaining: 1m 53s\n",
      "2200:\tlearn: 0.0038438\ttotal: 42.2s\tremaining: 1m 51s\n",
      "2300:\tlearn: 0.0036800\ttotal: 44s\tremaining: 1m 48s\n",
      "2400:\tlearn: 0.0035187\ttotal: 45.8s\tremaining: 1m 46s\n",
      "2500:\tlearn: 0.0033572\ttotal: 47.6s\tremaining: 1m 44s\n",
      "2600:\tlearn: 0.0032143\ttotal: 49.4s\tremaining: 1m 42s\n",
      "2700:\tlearn: 0.0030690\ttotal: 51.1s\tremaining: 1m 40s\n",
      "2800:\tlearn: 0.0029455\ttotal: 52.9s\tremaining: 1m 38s\n",
      "2900:\tlearn: 0.0028269\ttotal: 54.7s\tremaining: 1m 36s\n",
      "3000:\tlearn: 0.0026899\ttotal: 56.6s\tremaining: 1m 34s\n",
      "3100:\tlearn: 0.0025585\ttotal: 58.3s\tremaining: 1m 32s\n",
      "3200:\tlearn: 0.0024366\ttotal: 1m\tremaining: 1m 30s\n",
      "3300:\tlearn: 0.0023272\ttotal: 1m 2s\tremaining: 1m 28s\n",
      "3400:\tlearn: 0.0022260\ttotal: 1m 3s\tremaining: 1m 26s\n",
      "3500:\tlearn: 0.0021159\ttotal: 1m 5s\tremaining: 1m 24s\n",
      "3600:\tlearn: 0.0020273\ttotal: 1m 7s\tremaining: 1m 22s\n",
      "3700:\tlearn: 0.0019422\ttotal: 1m 9s\tremaining: 1m 20s\n",
      "3800:\tlearn: 0.0018429\ttotal: 1m 11s\tremaining: 1m 18s\n",
      "3900:\tlearn: 0.0017572\ttotal: 1m 13s\tremaining: 1m 16s\n",
      "4000:\tlearn: 0.0016693\ttotal: 1m 15s\tremaining: 1m 15s\n",
      "4100:\tlearn: 0.0015850\ttotal: 1m 16s\tremaining: 1m 13s\n",
      "4200:\tlearn: 0.0015041\ttotal: 1m 18s\tremaining: 1m 11s\n",
      "4300:\tlearn: 0.0014315\ttotal: 1m 20s\tremaining: 1m 9s\n",
      "4400:\tlearn: 0.0013674\ttotal: 1m 22s\tremaining: 1m 7s\n",
      "4500:\tlearn: 0.0013033\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "4600:\tlearn: 0.0012523\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "4700:\tlearn: 0.0012023\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "4800:\tlearn: 0.0011487\ttotal: 1m 31s\tremaining: 1m\n",
      "4900:\tlearn: 0.0010964\ttotal: 1m 33s\tremaining: 59.1s\n",
      "5000:\tlearn: 0.0010501\ttotal: 1m 35s\tremaining: 57.3s\n",
      "5100:\tlearn: 0.0010087\ttotal: 1m 37s\tremaining: 55.5s\n",
      "5200:\tlearn: 0.0009683\ttotal: 1m 40s\tremaining: 53.8s\n",
      "5300:\tlearn: 0.0009258\ttotal: 1m 42s\tremaining: 52.1s\n",
      "5400:\tlearn: 0.0008886\ttotal: 1m 44s\tremaining: 50.3s\n",
      "5500:\tlearn: 0.0008512\ttotal: 1m 46s\tremaining: 48.6s\n",
      "5600:\tlearn: 0.0008139\ttotal: 1m 49s\tremaining: 46.7s\n",
      "5700:\tlearn: 0.0007810\ttotal: 1m 51s\tremaining: 44.9s\n",
      "5800:\tlearn: 0.0007529\ttotal: 1m 53s\tremaining: 43s\n",
      "5900:\tlearn: 0.0007266\ttotal: 1m 55s\tremaining: 41.1s\n",
      "6000:\tlearn: 0.0006980\ttotal: 1m 57s\tremaining: 39.3s\n",
      "6100:\tlearn: 0.0006729\ttotal: 2m\tremaining: 37.4s\n",
      "6200:\tlearn: 0.0006521\ttotal: 2m 1s\tremaining: 35.4s\n",
      "6300:\tlearn: 0.0006283\ttotal: 2m 3s\tremaining: 33.4s\n",
      "6400:\tlearn: 0.0006089\ttotal: 2m 5s\tremaining: 31.5s\n",
      "6500:\tlearn: 0.0005872\ttotal: 2m 7s\tremaining: 29.4s\n",
      "6600:\tlearn: 0.0005689\ttotal: 2m 9s\tremaining: 27.5s\n",
      "6700:\tlearn: 0.0005502\ttotal: 2m 11s\tremaining: 25.5s\n",
      "6800:\tlearn: 0.0005345\ttotal: 2m 13s\tremaining: 23.5s\n",
      "6900:\tlearn: 0.0005194\ttotal: 2m 15s\tremaining: 21.6s\n",
      "7000:\tlearn: 0.0005028\ttotal: 2m 21s\tremaining: 20.3s\n",
      "7100:\tlearn: 0.0004893\ttotal: 2m 23s\tremaining: 18.2s\n",
      "7200:\tlearn: 0.0004732\ttotal: 2m 24s\tremaining: 16.1s\n",
      "7300:\tlearn: 0.0004592\ttotal: 2m 26s\tremaining: 14s\n",
      "7400:\tlearn: 0.0004477\ttotal: 2m 28s\tremaining: 12s\n",
      "7500:\tlearn: 0.0004348\ttotal: 2m 30s\tremaining: 10s\n",
      "7600:\tlearn: 0.0004251\ttotal: 2m 32s\tremaining: 8.02s\n",
      "7700:\tlearn: 0.0004143\ttotal: 2m 34s\tremaining: 6s\n",
      "7800:\tlearn: 0.0004019\ttotal: 2m 36s\tremaining: 3.98s\n",
      "7900:\tlearn: 0.0003923\ttotal: 2m 37s\tremaining: 1.98s\n",
      "7999:\tlearn: 0.0003815\ttotal: 2m 39s\tremaining: 0us\n",
      "AUC: 0.8723155720428293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Select only the selected features from X_train and X_test\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Train the model with the selected features\n",
    "clf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict the probabilities for X_test\n",
    "y_pred_proba = clf.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print the AUC value\n",
    "print(f'AUC: {auc_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2018580\ttotal: 30.3ms\tremaining: 4m 2s\n",
      "100:\tlearn: 0.0118331\ttotal: 3.58s\tremaining: 4m 40s\n",
      "200:\tlearn: 0.0108093\ttotal: 6.25s\tremaining: 4m 2s\n",
      "300:\tlearn: 0.0101697\ttotal: 8.63s\tremaining: 3m 40s\n",
      "400:\tlearn: 0.0096754\ttotal: 11.5s\tremaining: 3m 37s\n",
      "500:\tlearn: 0.0092172\ttotal: 14.2s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0088345\ttotal: 16.4s\tremaining: 3m 22s\n",
      "700:\tlearn: 0.0084611\ttotal: 18.5s\tremaining: 3m 13s\n",
      "800:\tlearn: 0.0081409\ttotal: 20.7s\tremaining: 3m 5s\n",
      "900:\tlearn: 0.0078504\ttotal: 22.8s\tremaining: 2m 59s\n",
      "1000:\tlearn: 0.0075824\ttotal: 24.8s\tremaining: 2m 53s\n",
      "1100:\tlearn: 0.0073076\ttotal: 27.1s\tremaining: 2m 49s\n",
      "1200:\tlearn: 0.0070488\ttotal: 29.3s\tremaining: 2m 46s\n",
      "1300:\tlearn: 0.0068061\ttotal: 32s\tremaining: 2m 44s\n",
      "1400:\tlearn: 0.0065781\ttotal: 34.2s\tremaining: 2m 41s\n",
      "1500:\tlearn: 0.0063651\ttotal: 36.9s\tremaining: 2m 39s\n",
      "1600:\tlearn: 0.0061413\ttotal: 39.1s\tremaining: 2m 36s\n",
      "1700:\tlearn: 0.0059372\ttotal: 41.7s\tremaining: 2m 34s\n",
      "1800:\tlearn: 0.0057315\ttotal: 43.9s\tremaining: 2m 31s\n",
      "1900:\tlearn: 0.0055435\ttotal: 46.1s\tremaining: 2m 27s\n",
      "2000:\tlearn: 0.0053520\ttotal: 48.2s\tremaining: 2m 24s\n",
      "2100:\tlearn: 0.0051870\ttotal: 50.4s\tremaining: 2m 21s\n",
      "2200:\tlearn: 0.0049926\ttotal: 52.5s\tremaining: 2m 18s\n",
      "2300:\tlearn: 0.0048039\ttotal: 54.6s\tremaining: 2m 15s\n",
      "2400:\tlearn: 0.0046228\ttotal: 56.8s\tremaining: 2m 12s\n",
      "2500:\tlearn: 0.0044593\ttotal: 59.1s\tremaining: 2m 9s\n",
      "2600:\tlearn: 0.0043030\ttotal: 1m 1s\tremaining: 2m 7s\n",
      "2700:\tlearn: 0.0041385\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "2800:\tlearn: 0.0039893\ttotal: 1m 6s\tremaining: 2m 2s\n",
      "2900:\tlearn: 0.0038491\ttotal: 1m 8s\tremaining: 2m\n",
      "3000:\tlearn: 0.0037251\ttotal: 1m 11s\tremaining: 1m 58s\n",
      "3100:\tlearn: 0.0036103\ttotal: 1m 13s\tremaining: 1m 56s\n",
      "3200:\tlearn: 0.0034842\ttotal: 1m 16s\tremaining: 1m 54s\n",
      "3300:\tlearn: 0.0033482\ttotal: 1m 20s\tremaining: 1m 54s\n",
      "3400:\tlearn: 0.0032369\ttotal: 1m 23s\tremaining: 1m 52s\n",
      "3500:\tlearn: 0.0031221\ttotal: 1m 25s\tremaining: 1m 50s\n",
      "3600:\tlearn: 0.0030140\ttotal: 1m 28s\tremaining: 1m 48s\n",
      "3700:\tlearn: 0.0029041\ttotal: 1m 31s\tremaining: 1m 46s\n",
      "3800:\tlearn: 0.0028134\ttotal: 1m 34s\tremaining: 1m 44s\n",
      "3900:\tlearn: 0.0027182\ttotal: 1m 46s\tremaining: 1m 51s\n",
      "4000:\tlearn: 0.0026239\ttotal: 1m 48s\tremaining: 1m 48s\n",
      "4100:\tlearn: 0.0025217\ttotal: 1m 51s\tremaining: 1m 45s\n",
      "4200:\tlearn: 0.0024325\ttotal: 1m 54s\tremaining: 1m 43s\n",
      "4300:\tlearn: 0.0023465\ttotal: 1m 57s\tremaining: 1m 40s\n",
      "4400:\tlearn: 0.0022684\ttotal: 2m\tremaining: 1m 38s\n",
      "4500:\tlearn: 0.0021924\ttotal: 2m 3s\tremaining: 1m 36s\n",
      "4600:\tlearn: 0.0021069\ttotal: 2m 6s\tremaining: 1m 33s\n",
      "4700:\tlearn: 0.0020338\ttotal: 2m 9s\tremaining: 1m 31s\n",
      "4800:\tlearn: 0.0019576\ttotal: 2m 12s\tremaining: 1m 28s\n",
      "4900:\tlearn: 0.0018914\ttotal: 2m 15s\tremaining: 1m 25s\n",
      "5000:\tlearn: 0.0018239\ttotal: 2m 18s\tremaining: 1m 22s\n",
      "5100:\tlearn: 0.0017617\ttotal: 2m 21s\tremaining: 1m 20s\n",
      "5200:\tlearn: 0.0016952\ttotal: 2m 24s\tremaining: 1m 17s\n",
      "5300:\tlearn: 0.0016398\ttotal: 2m 26s\tremaining: 1m 14s\n",
      "5400:\tlearn: 0.0015749\ttotal: 2m 29s\tremaining: 1m 12s\n",
      "5500:\tlearn: 0.0015207\ttotal: 2m 32s\tremaining: 1m 9s\n",
      "5600:\tlearn: 0.0014701\ttotal: 2m 34s\tremaining: 1m 6s\n",
      "5700:\tlearn: 0.0014151\ttotal: 2m 37s\tremaining: 1m 3s\n",
      "5800:\tlearn: 0.0013639\ttotal: 2m 40s\tremaining: 1m\n",
      "5900:\tlearn: 0.0013208\ttotal: 2m 42s\tremaining: 57.9s\n",
      "6000:\tlearn: 0.0012757\ttotal: 2m 45s\tremaining: 55.1s\n",
      "6100:\tlearn: 0.0012359\ttotal: 2m 48s\tremaining: 52.3s\n",
      "6200:\tlearn: 0.0011968\ttotal: 2m 50s\tremaining: 49.5s\n",
      "6300:\tlearn: 0.0011571\ttotal: 2m 53s\tremaining: 46.8s\n",
      "6400:\tlearn: 0.0011147\ttotal: 2m 56s\tremaining: 44s\n",
      "6500:\tlearn: 0.0010772\ttotal: 2m 58s\tremaining: 41.2s\n",
      "6600:\tlearn: 0.0010416\ttotal: 3m 1s\tremaining: 38.5s\n",
      "6700:\tlearn: 0.0010045\ttotal: 3m 4s\tremaining: 35.7s\n",
      "6800:\tlearn: 0.0009724\ttotal: 3m 6s\tremaining: 32.9s\n",
      "6900:\tlearn: 0.0009391\ttotal: 3m 9s\tremaining: 30.1s\n",
      "7000:\tlearn: 0.0009130\ttotal: 3m 11s\tremaining: 27.4s\n",
      "7100:\tlearn: 0.0008853\ttotal: 3m 14s\tremaining: 24.6s\n",
      "7200:\tlearn: 0.0008570\ttotal: 3m 16s\tremaining: 21.9s\n",
      "7300:\tlearn: 0.0008316\ttotal: 3m 19s\tremaining: 19.1s\n",
      "7400:\tlearn: 0.0008064\ttotal: 3m 21s\tremaining: 16.3s\n",
      "7500:\tlearn: 0.0007839\ttotal: 3m 24s\tremaining: 13.6s\n",
      "7600:\tlearn: 0.0007550\ttotal: 3m 27s\tremaining: 10.9s\n",
      "7700:\tlearn: 0.0007321\ttotal: 3m 29s\tremaining: 8.15s\n",
      "7800:\tlearn: 0.0007096\ttotal: 3m 32s\tremaining: 5.42s\n",
      "7900:\tlearn: 0.0006898\ttotal: 3m 35s\tremaining: 2.69s\n",
      "7999:\tlearn: 0.0006690\ttotal: 3m 37s\tremaining: 0us\n",
      "Accuracy on entire dataset: 0.9999593697434606\n",
      "ROC AUC Score on entire dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Select the features from the entire dataset\n",
    "X_selected = X_scaled_df[selected_features]\n",
    "\n",
    "# Train the model on the entire dataset with the selected features\n",
    "clf.fit(X_selected, y)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred = clf.predict(X_selected)\n",
    "y_pred_proba = clf.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy on entire dataset: {accuracy}\")\n",
    "print(f\"ROC AUC Score on entire dataset: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.49052188e-05, 5.04803945e-06, 1.82857351e-06, ...,\n",
       "       7.01016651e-06, 3.83121501e-05, 5.95773551e-06])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities for the test set\n",
    "X_testdata_scaled_df_selected=X_testdata_scaled_df[selected_features]\n",
    "y_pred_proba_testdata = clf.predict_proba(X_testdata_scaled_df_selected)[:, 1]\n",
    "\n",
    "y_pred_proba_testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities saved to test_set_with_probabilities.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.490522e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.048039e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.828574e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.412666e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.866371e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>35.781006</td>\n",
       "      <td>25.569364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.542014</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.421927e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>30.849795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.052665e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>61.872510</td>\n",
       "      <td>31.609595</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>155.783272</td>\n",
       "      <td>1</td>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826809</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.010167e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>58.722824</td>\n",
       "      <td>34.631254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174.474165</td>\n",
       "      <td>2</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969882</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.831215e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>72.825917</td>\n",
       "      <td>32.965867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>159.103290</td>\n",
       "      <td>1</td>\n",
       "      <td>606</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.957736e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0         300001  79.000000  17.122318   0   0   1  170.200000   1  700    0   \n",
       "1         300002  38.000000  43.693579   0   0   1  165.100000   1  814    0   \n",
       "2         300003  36.064225  23.998944   0   0   1  167.086735   1  662    0   \n",
       "3         300004  61.846764  31.693449   0   3   1  182.355708   2  862    0   \n",
       "4         300005  71.591991  20.086147   1   0   1  166.704917   2  335    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "105477    405478  35.781006  25.569364   0   0   1  158.542014   1  238    0   \n",
       "105478    405479  73.000000  30.849795   0   0   0  182.900000   1  114    0   \n",
       "105479    405480  61.872510  31.609595   0   4   1  155.783272   1  536    0   \n",
       "105480    405481  58.722824  34.631254   1   0   1  174.474165   2  517    0   \n",
       "105481    405482  72.825917  32.965867   0   0   1  159.103290   1  606    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73      X74  X75  X76  X77  X78  \\\n",
       "0       ...  0.030000  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "1       ...  0.040000  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "2       ...  0.006948  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "3       ...  0.033153  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "4       ...  0.004854  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "...     ...       ...  ...  ...       ...      ...  ...  ...  ...  ...   \n",
       "105477  ...  0.002452  0.0  0.0  0.000000  0.12259  0.0  0.0  0.0  0.0   \n",
       "105478  ...  0.730000  0.0  0.0  1.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "105479  ...  0.079609  0.0  0.0  0.826809  0.00000  0.0  0.0  0.0  0.0   \n",
       "105480  ...  0.000602  0.0  0.0  0.969882  0.00000  0.0  0.0  0.0  0.0   \n",
       "105481  ...  0.034720  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        Y_probability  \n",
       "0        7.490522e-05  \n",
       "1        5.048039e-06  \n",
       "2        1.828574e-06  \n",
       "3        2.412666e-04  \n",
       "4        2.866371e-06  \n",
       "...               ...  \n",
       "105477   3.421927e-07  \n",
       "105478   1.052665e-01  \n",
       "105479   7.010167e-06  \n",
       "105480   3.831215e-05  \n",
       "105481   5.957736e-06  \n",
       "\n",
       "[105482 rows x 79 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Y_probability'] = y_pred_proba_testdata\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "test_set[['RecordId', 'Y_probability']].to_csv('test_set_with_probabilities_cat.csv', index=False)\n",
    "\n",
    "print(\"Probabilities saved to test_set_with_probabilities.csv\")\n",
    "\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.49052188e-05 5.04803945e-06 1.82857351e-06 ... 7.01016651e-06\n",
      " 3.83121501e-05 5.95773551e-06]\n",
      "        RecordId  Y_probability\n",
      "0         300001   7.490522e-05\n",
      "1         300002   5.048039e-06\n",
      "2         300003   1.828574e-06\n",
      "3         300004   2.412666e-04\n",
      "4         300005   2.866371e-06\n",
      "...          ...            ...\n",
      "105477    405478   3.421927e-07\n",
      "105478    405479   1.052665e-01\n",
      "105479    405480   7.010167e-06\n",
      "105480    405481   3.831215e-05\n",
      "105481    405482   5.957736e-06\n",
      "\n",
      "[105482 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the generated CSV file\n",
    "csv_file_path = 'test_set_with_probabilities_cat.csv'\n",
    "test_set_with_probabilities = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get unique values in the Y_probability column\n",
    "unique_y_probabilities = test_set_with_probabilities['Y_probability'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_y_probabilities)\n",
    "print(test_set_with_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
